#!/usr/bin/env python3
"""
Experiment B: λ_comm sweep aggregator.

Given one or more metrics JSON files produced by the training scripts, collate
accuracy and commutator error statistics to trace the ε–accuracy frontier.
"""

from __future__ import annotations

import argparse
import json
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional


@dataclass
class SweepPoint:
    metrics_path: Path
    architecture: str
    dataset: str
    lambda_comm: float
    best_accuracy: float
    best_epoch: int
    best_comm_loss: Optional[float]
    final_comm_loss: Optional[float]


def load_metrics(path: Path) -> SweepPoint:
    data = json.loads(path.read_text(encoding='utf-8'))
    missing = [key for key in ('dataset', 'lambda_comm', 'best_accuracy') if key not in data]
    if missing:
        raise KeyError(f"Missing keys {missing} in metrics file '{path}'.")

    return SweepPoint(
        metrics_path=path,
        architecture=data.get('architecture', 'unknown'),
        dataset=data['dataset'],
        lambda_comm=float(data['lambda_comm']),
        best_accuracy=float(data['best_accuracy']),
        best_epoch=int(data.get('best_epoch', -1)),
        best_comm_loss=(None if data.get('best_comm_loss') is None else float(data['best_comm_loss'])),
        final_comm_loss=(None if data.get('final_comm_loss') is None else float(data['final_comm_loss'])),
    )


def format_row(point: SweepPoint) -> str:
    epsilon = point.best_comm_loss if point.best_comm_loss is not None else point.final_comm_loss
    epsilon_str = "n/a" if epsilon is None else f"{epsilon:.4e}"
    return (
        f"λ={point.lambda_comm:.6f} | acc={point.best_accuracy:6.2f}% | "
        f"ε={epsilon_str} | epoch={point.best_epoch:3d} | {point.architecture} [{point.metrics_path}]"
    )


def main() -> None:
    parser = argparse.ArgumentParser(description="Aggregate λ_comm sweep metrics.")
    parser.add_argument('--metrics', type=Path, nargs='+', required=True,
                        help="Metrics JSON files generated by train_mnist.py / train_cifar.py.")
    parser.add_argument('--sort-by', choices=['lambda', 'accuracy', 'epsilon'], default='lambda',
                        help="Ordering for the printed summary.")
    parser.add_argument('--output', type=Path, default=None,
                        help="Optional JSON file to store the aggregated sweep table.")
    args = parser.parse_args()

    points: List[SweepPoint] = [load_metrics(path) for path in args.metrics]
    if not points:
        print("No metrics files supplied.")
        return

    datasets = {point.dataset for point in points}
    if len(datasets) > 1:
        print(f"Warning: Multiple datasets detected in sweep: {sorted(datasets)}")

    sort_key = {
        'lambda': lambda p: p.lambda_comm,
        'accuracy': lambda p: -p.best_accuracy,
        'epsilon': lambda p: float('inf') if (p.best_comm_loss or p.final_comm_loss) is None
        else (p.best_comm_loss if p.best_comm_loss is not None else p.final_comm_loss),
    }[args.sort_by]
    points.sort(key=sort_key)

    print(f"\nλ_comm sweep ({points[0].dataset}, {points[0].architecture}...):")
    for point in points:
        print("  " + format_row(point))

    if args.output:
        args.output.parent.mkdir(parents=True, exist_ok=True)
        payload = [
            {
                'metrics_path': str(point.metrics_path),
                'architecture': point.architecture,
                'dataset': point.dataset,
                'lambda_comm': point.lambda_comm,
                'best_accuracy': point.best_accuracy,
                'best_epoch': point.best_epoch,
                'best_comm_loss': point.best_comm_loss,
                'final_comm_loss': point.final_comm_loss,
            }
            for point in points
        ]
        args.output.write_text(json.dumps(payload, indent=2), encoding='utf-8')
        print(f"\nSaved sweep summary to {args.output}")


if __name__ == '__main__':
    main()
