\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{enumitem}

\title{Equivariant Structured Positional Rotations:\\Complete Algebraic Derivation}
\author{}
\date{}

\newcommand{\eqdef}{\overset{\varnothing}{=}}
\newcommand{\ProofBlock}[3]{%
  \begin{equation*}
    \boxed{[#1]}\;
    \begin{aligned}[t]
      #2
    \end{aligned}
    \qquad [\mathrm{deps}: #3]
  \end{equation*}
}
\newcommand{\Note}[1]{\text{(#1)}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Complex}{\mathbb{C}}

\begin{document}

\maketitle

\begin{abstract}
This document provides a complete, boxed derivation of the relative-position property for equivariant structured positional rotations in attention mechanisms.  Each step is recorded as a labelled statement \([T\cdot]\) with explicit dependencies so that the argument can be followed mechanically.
\end{abstract}

\tableofcontents
\newpage

\section{Tier 0: Linear-Algebra Primitives}

\ProofBlock{T0.1:\mathbb{N},\mathrm{Idx}}{
\mathbb{N} \eqdef \{1,2,3,\dots\}\\
d_h,d_c,D \in \mathbb{N}\\
H \eqdef \{1,\dots,d_h\},\quad
K \eqdef \{1,\dots,d_c\},\quad
J_D \eqdef \{1,\dots,D\}
}{\varnothing}

\ProofBlock{T0.2:I_n,\delta_{ij}}{
\delta_{ij} \eqdef
\begin{cases}
1,& i=j,\\
0,& i\neq j,
\end{cases}\\
I_n \eqdef [\delta_{ij}]_{i,j=1}^n
}{T0.1}

\ProofBlock{T0.3:\mathbb{R}^{m\times n},(\cdot)^\top,(\cdot)^*,\mathrm{tr}}{
\Real^{m\times n} \eqdef \text{set of } m\times n \text{ real matrices}\\
\Complex^{m\times n} \eqdef \text{set of } m\times n \text{ complex matrices}\\
A^\top \in \Real^{n\times m} \quad (A\in \Real^{m\times n})\\
B^* \eqdef \overline{B}^{\top} \quad (B\in \Complex^{m\times n})\\
\operatorname{tr}(M) \eqdef \sum_{i=1}^n M_{ii} \quad (M\in \Complex^{n\times n})
}{T0.1}

\ProofBlock{T0.4:\det}{
\det : \Complex^{n\times n}\to\Complex\\
\det(AB)=\det(A)\det(B)\\
\det(A^\top)=\det(A)\\
U\text{ invertible} \Rightarrow \det(UAU^{-1})=\det(A)\\
\Note{multiplicativity, transpose invariance, similarity invariance}
}{T0.3}

\ProofBlock{T0.5:\oplus,\mathrm{blk},\det\oplus}{
\bigoplus_{u=1}^m M_u \eqdef \mathrm{diag}(M_1,\dots,M_m)\\
\det\!\left(\bigoplus_{u=1}^m M_u\right) = \prod_{u=1}^m \det(M_u)\\
\Note{block triangular matrices have determinant equal to product of block determinants}
}{T0.4}

\ProofBlock{T0.6:O,SO,U}{
O(n) \eqdef \{Q\in\Real^{n\times n} \mid Q^\top Q = I_n\}\\
SO(n) \eqdef \{Q\in O(n) \mid \det Q = 1\}\\
U(n) \eqdef \{W\in\Complex^{n\times n} \mid W^*W = I_n\}\\
Q\in O(n) \Rightarrow Q^{-1} = Q^\top
}{T0.2,T0.3,T0.4}

\ProofBlock{T0.7:\det O}{
Q\in O(n) \Rightarrow (\det Q)^2 = \det(Q^\top Q) = \det(I_n)=1\\
\Rightarrow \det Q \in \{\pm 1\}
}{T0.6,T0.4}

\ProofBlock{T0.8:\sigma,\sigma_{\min},\text{normal}}{
\sigma(M) \eqdef \{\lambda\in\Complex \mid \exists x\neq 0: Mx=\lambda x\}\\
M^*M = MM^* \Rightarrow M \text{ normal}\\
\text{Singular values } s_i(M) \eqdef \sqrt{\sigma_i(M^*M)}\\
\sigma_{\min}(M) \eqdef \min_i s_i(M)\\
M \text{ normal} \Rightarrow s_i(M)=|\lambda_i| \text{ for } \lambda_i \in \sigma(M)\\
\Note{unitary diagonalisation of normal matrices}
}{T0.3}

\ProofBlock{T0.9:|\cdot|,|\cdot|_1}{
|x| \eqdef \left(\sum_{u} x_u^2\right)^{1/2} \quad (x\in\Real^m)\\
|x|_1 \eqdef \sum_{u} |x_u|\\
|M| \eqdef \sup_{v\neq 0}\frac{|Mv|}{|v|} \quad (M\in\Real^{m\times n})\\
|AB|\le |A|\,|B|,\quad |A+B|\le |A|+|B|\\
|a| \eqdef \lvert a\rvert \quad (a\in\Real)\\
\Note{overloaded notation chooses scalar, vector, or operator norm from context}
}{T0.8}

\ProofBlock{T0.10:[A,B]}{
[A,B] \eqdef AB-BA
}{T0.3}

\ProofBlock{T0.11:\exp,\log,\exp\text{ props}}{
\exp(M) \eqdef \sum_{t\ge 0}\frac{1}{t!}M^t\\
\log(X) \text{ locally defined as } \exp^{-1}(X) \text{ near } I_n\\
[A,B]=0 \Rightarrow \exp(A+B)=\exp(A)\exp(B)\\
(\exp M)^\top = \exp(M^\top)\\
U \text{ invertible} \Rightarrow \exp(UMU^{-1})=U\exp(M)U^{-1}\\
\det(\exp M)=\exp(\operatorname{tr} M)\\
\exp\!\left(\bigoplus_{u=1}^m M_u\right) = \bigoplus_{u=1}^m \exp(M_u)\\
\Note{all properties follow from the power-series definition}
}{T0.3,T0.4,T0.5,T0.10}

\ProofBlock{T0.12:\mathcal{C},O(\cdot),\approx_\varepsilon}{
\mathcal{C} \eqdef \{C,C',C'',\dots \mid C\ge 0 \text{ finite constants}\}\\
f = O(g) \Leftrightarrow \exists C\in\mathcal{C}: f\le Cg\\
X \approx_\varepsilon Y \Leftrightarrow |X-Y|\le \varepsilon
}{T0.9}

\ProofBlock{T0.13:\mathrm{BCH}}{
\exp(M)\exp(N) = \exp\!\left(M+N+\tfrac12[M,N]+R(M,N)\right)\\
|R(M,N)| = O(|[M,N]|^2)\\
\Note{Baker--Campbell--Hausdorff series (local version)}
}{T0.11,T0.10,T0.12,T0.9}

\ProofBlock{T0.14:\ker,\mathrm{im},\mathrm{rank}}{
\ker(M) \eqdef \{x \mid Mx=0\}\\
\mathrm{im}(M) \eqdef \{Mx \mid x\}\\
\mathrm{rank}(M) \eqdef \dim(\mathrm{im}(M))
}{T0.3,T0.1}

\ProofBlock{T0.15:\mathrm{proj}}{
P^2 = P \text{ and } P^\top = P \Rightarrow P \text{ orthogonal projector}\\
P,Q \text{ orthogonal projectors and } PQ=0 \Rightarrow \mathrm{im}(P)\perp \mathrm{im}(Q)\\
\Note{characterisation via images}
}{T0.14,T0.3}

\ProofBlock{T0.16:\mathrm{skew}_\mathrm{spec}}{
S^\top = -S \Rightarrow S \text{ normal}\\
\sigma(S)\subset i\Real\\
\lambda = i\mu \in \sigma(S) \Rightarrow -\lambda = -i\mu \in \sigma(S)\\
\Note{skew-symmetric spectra occur in conjugate-sign pairs}
}{T0.3,T0.8}

\ProofBlock{T0.17:J,R_2}{
J \eqdef
\begin{bmatrix}
0 & -1\\
1 & 0
\end{bmatrix},\qquad
R_2(\theta) \eqdef \exp(\theta J)
}{T0.11}

\ProofBlock{T0.18:R_2\in SO(2)}{
R_2(\theta)^\top R_2(\theta) = I_2\\
\det R_2(\theta) = 1\\
\Rightarrow R_2(\theta)\in SO(2)\\
\Note{uses $J^\top=-J$ and properties of $\exp$ and the determinant}
}{T0.17,T0.16,T0.11,T0.6,T0.4,T0.7}

\ProofBlock{T0.19:\mathrm{Weyl}}{
\bigl|\sigma_{\min}(A+E) - \sigma_{\min}(A)\bigr| \le |E|
}{T0.8,T0.9}

\ProofBlock{T0.20:(X^{-1})^\top}{
X \text{ invertible } \Rightarrow (X^{-1})^\top = (X^\top)^{-1}
}{T0.3}

\section{Tier 1: Structured Generators}

\ProofBlock{T1.1:L_k}{
\forall k\in K:\ L_k \in \Real^{d_h\times d_h},\quad L_k^\top = -L_k,\quad [L_a,L_b]=0\\
\Note{model hypothesis: commuting skew-symmetric generators}
}{T0.1,T0.3,T0.10,T0.16}

\ProofBlock{T1.2:\mathrm{normal}\ L_k}{
L_k^\top = -L_k \Rightarrow L_k \text{ normal}
}{T1.1,T0.16}

\ProofBlock{T1.3:A(r)}{
r\in \Real^{d_c} \Rightarrow A(r) \eqdef \sum_{k=1}^{d_c} r_k L_k
}{T1.1,T0.1}

\ProofBlock{T1.4:A(r)^\top}{
A(r)^\top = -A(r)
}{T1.3,T1.1,T0.3}

\ProofBlock{T1.5:[A(r),A(s)]}{
[A(r),A(s)] = 0
}{T1.3,T1.1,T0.10}

\ProofBlock{T1.6:R_{\mathrm{STR}}}{
R_{\mathrm{STR}}(r) \eqdef \exp(A(r))
}{T1.3,T0.11}

\section{Tier 2: Joint Block Structure}

\ProofBlock{T2.1:\mathrm{sim}\text{-}\mathrm{unitary}}{
\{L_k\}_{k\in K} \text{ commute and are normal}\\
\Rightarrow \exists \mathcal{U}_c \in U(d_h):\ \mathcal{U}_c^* L_k \mathcal{U}_c = \mathrm{diag}(i\lambda_{k,1},\dots,i\lambda_{k,d_h})\\
\lambda_{k,j}\in\Real
}{T1.2,T1.1,T0.6,T0.16}

\ProofBlock{T2.2:\mathrm{real}\ 2\text{D}\ \mathrm{planes}}{
\text{Fix } j\in H:\ \mathcal{U}_c^*L_k\mathcal{U}_c e_j = i\lambda_{k,j} e_j\\
\Rightarrow L_k(\Re e_j) = \lambda_{k,j} J (\Re e_j,\Im e_j)\\
L_k(\Im e_j) = \lambda_{k,j} J (\Re e_j,\Im e_j)\\
\Rightarrow \mathrm{span}\{\Re e_j,\Im e_j\} \text{ is a real, }2\text{-D, }L_k\text{-invariant plane}
}{T2.1,T0.17,T0.16,T0.3}

\ProofBlock{T2.3:\mathrm{JointBlockDiag}}{
\exists m,d_{\mathrm{null}}\in\mathbb{N}:\ 2m+d_{\mathrm{null}}=d_h\\
\exists U\in O(d_h):\ U^\top L_k U
 = \left(\bigoplus_{u=1}^m \lambda_{k,u} J\right)\oplus 0_{d_{\mathrm{null}}\times d_{\mathrm{null}}}
}{T2.2,T0.6,T0.16,T0.5}

\ProofBlock{T2.4:\beta,\theta}{
\beta_u \eqdef (\lambda_{1,u},\dots,\lambda_{d_c,u})^\top \in \Real^{d_c}\\
\theta_u(r) \eqdef \beta_u^\top r \in \Real
}{T2.3,T1.1,T0.1}

\ProofBlock{T2.5:U^\top A(r)U}{
U^\top A(r) U = \left(\bigoplus_{u=1}^m \theta_u(r) J\right)\oplus 0_{d_{\mathrm{null}}\times d_{\mathrm{null}}}
}{T1.3,T2.3,T2.4,T0.17,T0.5}

\ProofBlock{T2.6:\exp\mathrm{blk}}{
\exp\!\big(U^\top A(r) U\big)
 = \left(\bigoplus_{u=1}^m R_2(\theta_u(r))\right)\oplus I_{d_{\mathrm{null}}}
}{T2.5,T0.17,T0.11,T0.5}

\ProofBlock{T2.7:R_{\mathrm{STR}}\text{ form}}{
R_{\mathrm{STR}}(r)
 = U\left[\left(\bigoplus_{u=1}^m R_2(\theta_u(r))\right)\oplus I_{d_{\mathrm{null}}}\right]U^\top
}{T1.6,T2.6,T0.11,T2.3}

\ProofBlock{T2.8:R_{\mathrm{STR}}\in SO}{
R_{\mathrm{STR}}(r)\in SO(d_h)\\
\Note{uses $R_2(\theta)\in SO(2)$, block determinant multiplicativity, and $U\in O(d_h)$}
}{T2.7,T0.18,T0.5,T2.3,T0.6,T0.7,T0.4}

\ProofBlock{T2.9:\mathrm{rel}\ R_{\mathrm{STR}}}{
R_{\mathrm{STR}}(r_i)^\top R_{\mathrm{STR}}(r_j) = R_{\mathrm{STR}}(r_j-r_i)
}{T1.4,T1.5,T1.6,T0.11}

\ProofBlock{T2.10:\Pi_{\mathrm{act}},\Pi_{\mathrm{null}},d_{\mathrm{act}}}{
\Pi_{\mathrm{act}} \eqdef U\,\mathrm{diag}(I_{2m},0)\,U^\top\\
\Pi_{\mathrm{null}} \eqdef U\,\mathrm{diag}(0,I_{d_{\mathrm{null}}})\,U^\top\\
\Pi_{\mathrm{act}}^\top = \Pi_{\mathrm{act}},\ \Pi_{\mathrm{act}}^2 = \Pi_{\mathrm{act}}\\
\Pi_{\mathrm{null}}^\top = \Pi_{\mathrm{null}},\ \Pi_{\mathrm{null}}^2 = \Pi_{\mathrm{null}}\\
\Pi_{\mathrm{act}}\Pi_{\mathrm{null}} = 0 \Rightarrow \mathrm{im}(\Pi_{\mathrm{act}})\perp \mathrm{im}(\Pi_{\mathrm{null}})\\
d_{\mathrm{act}} \eqdef \mathrm{rank}(\Pi_{\mathrm{act}}) = 2m
}{T2.3,T0.15,T0.2,T0.14,T0.6}

\ProofBlock{T2.11:\Pi_{\mathrm{act}}\ \mathrm{comm}}{
R_{\mathrm{STR}}(r)\Pi_{\mathrm{act}} = \Pi_{\mathrm{act}} R_{\mathrm{STR}}(r)
}{T2.7,T2.10,T0.5,T0.6}

\section{Tier 3: Cayley Post-Rotations}

\ProofBlock{T3.1:\mathrm{Cayley}}{
S\in\Real^{d_h\times d_h},\ S^\top = -S \Rightarrow (I+S) \text{ invertible}\\
P_{\mathrm{sp}} \eqdef (I-S)(I+S)^{-1}\\
(I-S)(I+S) = (I+S)(I-S) = I-S^2\\
\Note{uses $\sigma(S)\subset i\Real$ so $1+i\mu\neq 0$}
}{T0.16,T0.3,T0.2}

\ProofBlock{T3.2:P_{\mathrm{sp}}\in SO,\mathcal{B}}{
P_{\mathrm{sp}}^\top = ((I+S)^{-1})^\top (I-S)^\top = I\\
\det(P_{\mathrm{sp}}) = \prod_u \frac{1-i\mu_u}{1+i\mu_u} = 1\\
\mathcal{B} \eqdef \{(I-S)(I+S)^{-1} \mid S^\top = -S\} \subseteq SO(d_h)
}{T3.1,T0.16,T0.20,T0.7,T0.6,T0.4,T0.11}

\ProofBlock{T3.3:\mathrm{Cayley}\ \mathrm{surj}}{
Q\in SO(d_h),\ -1\notin \sigma(Q) \Rightarrow S_Q \eqdef (I-Q)(I+Q)^{-1}\\
S_Q^\top = -S_Q,\quad (I-S_Q)(I+S_Q)^{-1} = Q\\
\Note{Cayley transform bijection on $SO(d_h)$ with no $-1$ eigenvalues}
}{T0.16,T0.20,T0.6,T0.4,T0.11,T0.7}

\ProofBlock{T3.4:\mathcal{A}}{
\mathcal{A} \eqdef \Big\{U\,\mathrm{diag}(I_{2m}, R_{\mathrm{null}})\,U^\top \,\Big|\,
R_{\mathrm{null}}\in SO(d_{\mathrm{null}})\Big\} \subseteq SO(d_h)\\
R_{\mathrm{null}}\in SO(d_{\mathrm{null}}),\ -1\notin \sigma(R_{\mathrm{null}})
\Rightarrow U\,\mathrm{diag}(I_{2m}, R_{\mathrm{null}})\,U^\top \in \mathcal{B}
}{T2.3,T0.6,T0.7,T0.5,T0.4,T0.18,T3.3}

\ProofBlock{T3.5:R_{\mathrm{sp}}}{
R_{\mathrm{sp}}(r) \eqdef R_{\mathrm{STR}}(r)P_{\mathrm{sp}}\\
R_{\mathrm{STR}}(r)\in SO(d_h),\ P_{\mathrm{sp}}\in SO(d_h)
\Rightarrow R_{\mathrm{sp}}(r)\in SO(d_h)
}{T2.8,T3.2,T0.6,T0.4}

\ProofBlock{T3.6:\Pi_{\mathrm{act}} R_{\mathrm{sp}} \Pi_{\mathrm{act}}}{
P_{\mathrm{sp}}\in \mathcal{A} \Rightarrow
\Pi_{\mathrm{act}}P_{\mathrm{sp}} = \Pi_{\mathrm{act}} = P_{\mathrm{sp}}\Pi_{\mathrm{act}}\\
R_{\mathrm{STR}}(r)\Pi_{\mathrm{act}} = \Pi_{\mathrm{act}} R_{\mathrm{STR}}(r)\\
\Rightarrow \Pi_{\mathrm{act}}R_{\mathrm{sp}}(r)\Pi_{\mathrm{act}}
= \Pi_{\mathrm{act}}R_{\mathrm{STR}}(r)\Pi_{\mathrm{act}}
}{T3.5,T2.10,T2.11,T3.4,T0.5,T0.6}

\ProofBlock{T3.7:\Pi\text{-}\mathrm{rel}\ R_{\mathrm{sp}}}{
P_{\mathrm{sp}}\in \mathcal{A} \Rightarrow
\Pi_{\mathrm{act}}R_{\mathrm{sp}}(r_i)^\top R_{\mathrm{sp}}(r_j)\Pi_{\mathrm{act}}
= \Pi_{\mathrm{act}}R_{\mathrm{STR}}(r_j-r_i)\Pi_{\mathrm{act}}
}{T3.6,T2.9,T3.5,T3.2,T2.10,T0.6,T0.4}

\section{Tier 4: Attention Queries, Keys, and Scores}

\ProofBlock{T4.1:W,q,k,v}{
W_Q,W_K,W_V \in \Real^{d_h\times D}\\
x_i\in\Real^D,\ r_i\in\Real^{d_c}\\
q_i = W_Q x_i,\quad k_j = W_K x_j,\quad v_j = W_V x_j
}{T0.1,T0.3}

\ProofBlock{T4.2:q^{(\mathrm{act})},k^{(\mathrm{act})},d_{\mathrm{act}}}{
q_i^{(\mathrm{act})} \eqdef \Pi_{\mathrm{act}} q_i,\quad
k_j^{(\mathrm{act})} \eqdef \Pi_{\mathrm{act}} k_j\\
d_{\mathrm{act}} \eqdef 2m
}{T2.10,T4.1}

\ProofBlock{T4.3:\tilde q,\tilde k}{
\tilde q_i = \Pi_{\mathrm{act}} R_{\mathrm{sp}}(r_i) q_i^{(\mathrm{act})}\\
\tilde k_j = \Pi_{\mathrm{act}} R_{\mathrm{sp}}(r_j) k_j^{(\mathrm{act})}
}{T3.5,T4.2,T2.10}

\ProofBlock{T4.4:\alpha_{ij}\ \mathrm{def}}{
\alpha_{ij} \eqdef \frac{\tilde q_i^\top \tilde k_j}{\sqrt{d_{\mathrm{act}}}}\\
= \frac{1}{\sqrt{d_{\mathrm{act}}}}
(q_i^{(\mathrm{act})})^\top
\big(\Pi_{\mathrm{act}}R_{\mathrm{sp}}(r_i)\Pi_{\mathrm{act}}\big)^\top
\big(\Pi_{\mathrm{act}}R_{\mathrm{sp}}(r_j)\Pi_{\mathrm{act}}\big)
k_j^{(\mathrm{act})}\\
\Note{uses $\Pi_{\mathrm{act}}^\top = \Pi_{\mathrm{act}} = \Pi_{\mathrm{act}}^2$}
}{T4.3,T4.2,T2.10,T0.3}

\ProofBlock{T4.5:\alpha_{ij}\ \mathrm{rel}}{
P_{\mathrm{sp}}\in\mathcal{A} \Rightarrow
\alpha_{ij}
= \frac{1}{\sqrt{2m}}
(q_i^{(\mathrm{act})})^\top
\Big(\Pi_{\mathrm{act}}R_{\mathrm{STR}}(r_j-r_i)\Pi_{\mathrm{act}}\Big)
k_j^{(\mathrm{act})}
}{T4.4,T3.6,T3.7,T4.2,T2.9,T2.10,T0.3}

\section{Tier 5: Stability Estimates}

\ProofBlock{T5.1:\varepsilon\ \mathrm{comm}}{
\varepsilon_{ab} \eqdef |[L_a,L_b]|,\quad \varepsilon \eqdef \max_{a,b}\varepsilon_{ab}\\
\bigl|[A(r),A(s)]\bigr|
\le \sum_{a,b}|r_a||s_b|\varepsilon_{ab}
\le |r|_1|s|_1\,\varepsilon
}{T1.3,T1.1,T0.10,T0.9}

\ProofBlock{T5.2:\mathrm{BCH}\ \mathrm{err}}{
\left|
\log\!\big(\exp(A(r))\exp(A(s))\big) - (A(r)+A(s))
\right|
\le \tfrac12 |[A(r),A(s)]| + C |[A(r),A(s)]|^2
}{T0.13,T5.1,T0.12,T0.11,T0.9}

\ProofBlock{T5.3:R_{\mathrm{STR}}\ \mathrm{rel}\ \mathrm{approx}}{
\bigl|
R_{\mathrm{STR}}(r)^\top R_{\mathrm{STR}}(s) - R_{\mathrm{STR}}(s-r)
\bigr|
\le C\,\varepsilon\,|r|_1 |s|_1 + O(\varepsilon^2)
}{T1.6,T1.4,T1.5,T5.2,T5.1,T0.11,T0.12,T0.9}

\ProofBlock{T5.4:S=S_-+E}{
S = S_- + E,\quad S_-^\top = -S_-,\quad |E|\le \eta,\quad 0\le \eta < 1
}{T0.16,T0.9}

\ProofBlock{T5.5:\sigma_{\min}(I+S_-)}{
S_-^\top = -S_- \Rightarrow \sigma(S_-)\subset i\Real\\
\Rightarrow |1+i\mu|\ge 1 \text{ for } \lambda=i\mu \in \sigma(S_-)\\
\sigma_{\min}(I+S_-)\ge 1
}{T5.4,T0.16,T0.8}

\ProofBlock{T5.6:\sigma_{\min}(I+S)}{
\sigma_{\min}(I+S) \ge \sigma_{\min}(I+S_-) - |E| \ge 1-\eta > 0\\
\Rightarrow I+S \text{ invertible}
}{T5.4,T5.5,T0.19,T0.9}

\ProofBlock{T5.7:\mathrm{Cayley}\ \mathrm{Lip}}{
P_{\mathrm{sp}}(S) \eqdef (I-S)(I+S)^{-1},\quad
P_{\mathrm{sp}}(S_-) \eqdef (I-S_-)(I+S_-)^{-1}\\
|P_{\mathrm{sp}}(S) - P_{\mathrm{sp}}(S_-)| \le C'\eta
}{T5.6,T5.4,T0.20,T0.9,T0.12}

\ProofBlock{T5.8:\eta_{\mathrm{mix}}}{
P_{\mathrm{sp}} = U
\begin{bmatrix}
A & B\\
C & D
\end{bmatrix}
U^\top,\quad \eta_{\mathrm{mix}} \eqdef |B| + |C|\\
P_{\mathrm{sp}}\in SO(d_h)\Rightarrow
\begin{bmatrix}
A & B\\
C & D
\end{bmatrix}^\top
\begin{bmatrix}
A & B\\
C & D
\end{bmatrix} = I\\
\Rightarrow |A-I_{2m}| \le C''\eta_{\mathrm{mix}}\\
\Rightarrow |\Pi_{\mathrm{act}}P_{\mathrm{sp}}\Pi_{\mathrm{act}} - \Pi_{\mathrm{act}}|\le C''\eta_{\mathrm{mix}}
}{T3.2,T2.3,T2.10,T0.9,T0.6,T0.5,T0.7}

\ProofBlock{T5.9:\Pi R_{\mathrm{sp}}\Pi\ \mathrm{approx}}{
\bigl|
\Pi_{\mathrm{act}}R_{\mathrm{sp}}(r)\Pi_{\mathrm{act}}
- \Pi_{\mathrm{act}}R_{\mathrm{STR}}(r)\Pi_{\mathrm{act}}
\bigr|
\le C''\eta_{\mathrm{mix}}
}{T3.5,T2.11,T5.8,T2.10,T0.9,T0.6}

\ProofBlock{T5.10:\alpha_{ij}\ \mathrm{stab}}{
\Delta_{ij} \eqdef C\big(\varepsilon |r_i|_1 |r_j|_1 + \eta_{\mathrm{mix}}\big)
|q_i^{(\mathrm{act})}|\,|k_j^{(\mathrm{act})}|\\
\left|
\alpha_{ij} -
\frac{1}{\sqrt{2m}}
(q_i^{(\mathrm{act})})^\top
\Big(\Pi_{\mathrm{act}}R_{\mathrm{STR}}(r_j-r_i)\Pi_{\mathrm{act}}\Big)
k_j^{(\mathrm{act})}
\right|
\le \Delta_{ij}
}{T4.4,T5.9,T5.3,T4.2,T5.1,T0.12,T0.9,T2.10}

\section{Tier 6: Conclusions}

\ProofBlock{T6.1:\mathrm{GOAL}}{
\big(T1.1 \wedge T2.3 \wedge P_{\mathrm{sp}}\in\mathcal{A}\big)
\Rightarrow
\alpha_{ij}
= \frac{1}{\sqrt{2m}}
(q_i^{(\mathrm{act})})^\top
\Big(\Pi_{\mathrm{act}}R_{\mathrm{STR}}(r_j-r_i)\Pi_{\mathrm{act}}\Big)
k_j^{(\mathrm{act})}
}{T4.5,T3.4,T2.3,T1.1,T2.10}

\ProofBlock{T6.2:\mathrm{GOAL}_{\mathrm{rob}}}{
\Big(
|[L_a,L_b]|\le \varepsilon\ \forall a,b,\quad
P_{\mathrm{sp}}\in SO(d_h)\ \text{with mixing }\eta_{\mathrm{mix}}
\Big)
\Rightarrow
\alpha_{ij} \approx_{\Delta_{ij}}
\frac{1}{\sqrt{2m}}
(q_i^{(\mathrm{act})})^\top
\Big(\Pi_{\mathrm{act}}R_{\mathrm{STR}}(r_j-r_i)\Pi_{\mathrm{act}}\Big)
k_j^{(\mathrm{act})}\\
\Delta_{ij} \le C\big(\varepsilon |r_i|_1 |r_j|_1 + \eta_{\mathrm{mix}}\big)
|q_i^{(\mathrm{act})}|\,|k_j^{(\mathrm{act})}|
}{T5.10,T0.12,T5.1,T5.8,T4.2,T2.10}

\end{document}
\section{Tier 7: Positive Random Features and Variance Bounds}

\ProofBlock{T7.0:\mathcal{N}(0,I_n),\mathbb{E},\mathrm{Var}}{
\mathcal{N}(0,I_n) \eqdef \text{the mean-zero Gaussian law on }\Real^n\text{ with density } (2\pi)^{-n/2}\exp\!\big(-\tfrac12|w|^2\big)\\[4pt]
w\sim\mathcal{N}(0,I_n) \Rightarrow \mathbb{E}[w] = 0,\quad \mathbb{E}[w w^\top] = I_n\\[4pt]
\mathbb{E}[\cdot] \eqdef \text{expectation with respect to the (joint) law of all Gaussian draws }w\\
\mathrm{Var}[Z] \eqdef \mathbb{E}[Z^2] - (\mathbb{E}[Z])^2 \quad\text{for any scalar random variable }Z
}{T0.9,T0.3,T0.1}

\ProofBlock{T7.1:\mathrm{RF\ setup}}{
d_{\mathrm{act}} = 2m \text{ from T2.10}\\[4pt]
	ext{For probabilistic estimates we draw } w \sim \mathcal{N}(0,I_{d_{\mathrm{act}}}) \text{ in the sense of T7.0}\\[4pt]
\phi_w(x) \eqdef \exp\!\Big(w^\top x - \tfrac12 |x|^2\Big) \quad (x\in\Real^{d_{\mathrm{act}}})\\
\Note{positive softmax random feature map as in FAVOR\,+ estimators}\\[4pt]
Z(x,y;w) \eqdef \phi_w(x)\,\phi_w(y) = \exp\!\Big(w^\top(x+y) - \tfrac12(|x|^2+|y|^2)\Big) \quad (x,y\in\Real^{d_{\mathrm{act}}})\\[4pt]
\widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(x,y) \eqdef \frac{1}{n_{\mathrm{rf}}} \sum_{t=1}^{n_{\mathrm{rf}}} Z(x,y;w_t) \quad \text{for }n_{\mathrm{rf}}\in\mathbb{N},\ w_t \text{ i.i.d. } \mathcal{N}(0,I_{d_{\mathrm{act}}})\\[4pt]
\Note{ \widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(x,y) \text{ is our Monte Carlo estimator of } \exp(x^\top y) \text{ (unnormalized softmax kernel)} }
}{T2.10,T7.0,T0.3,T0.9,T0.1}

\ProofBlock{T7.2:\widehat q_i,\widehat k_j,\alpha_{ij}}{
	ilde q_i,\tilde k_j \text{ from T4.3},\quad q_i^{(\mathrm{act})},k_j^{(\mathrm{act})} \text{ from T4.2}\\[4pt]
\alpha_{ij} \eqdef \frac{1}{\sqrt{d_{\mathrm{act}}}}\tilde q_i^\top \tilde k_j \quad\text{from T4.4 and T2.10}\\[4pt]
\widehat q_i \eqdef d_{\mathrm{act}}^{-1/4}\,\tilde q_i, \quad \widehat k_j \eqdef d_{\mathrm{act}}^{-1/4}\,\tilde k_j\\[4pt]
\widehat q_i^\top \widehat k_j = (d_{\mathrm{act}}^{-1/4}\tilde q_i)^\top (d_{\mathrm{act}}^{-1/4}\tilde k_j) = d_{\mathrm{act}}^{-1/2} \tilde q_i^\top \tilde k_j = \alpha_{ij}\\[4pt]
\Rightarrow \alpha_{ij} = \widehat q_i^\top \widehat k_j\\[4pt]
\Note{ The attention logit \(\alpha_{ij}\) is \emph{exactly} a Euclidean dot product between \(\widehat q_i,\widehat k_j \in \Real^{d_{\mathrm{act}}}\), with no remaining \(\tfrac{1}{\sqrt{d_{\mathrm{act}}}}\) factor. }
}{T4.3,T4.4,T4.2,T2.10,T0.9,T0.1}

\ProofBlock{T7.3:\mathbb{E}Z=\exp(x^\top y),\text{unbiasedness}}{
	ext{Fix } x,y\in\Real^{d_{\mathrm{act}}}. \ Z(x,y;w) = \exp\!\Big( w^\top(x+y) - \tfrac12(|x|^2+|y|^2) \Big)\\[4pt]
	ext{For } w\sim\mathcal{N}(0,I_{d_{\mathrm{act}}}) \text{ (T7.0), } w^\top(x+y) \text{ is scalar Gaussian with mean }0\text{ and variance }|x+y|^2.\\[4pt]
\mathbb{E}_w\big[\exp(u^\top w)\big] = \exp\!\Big(\tfrac12|u|^2\Big) \quad \text{for any fixed }u\in\Real^{d_{\mathrm{act}}} \text{ (Gaussian MGF).}\\[4pt]
\Rightarrow \mathbb{E}[Z(x,y;w)] = \exp\!\Big( \tfrac12|x+y|^2 - \tfrac12(|x|^2+|y|^2) \Big)\\[4pt]
|x+y|^2 = |x|^2+|y|^2+2 x^\top y \quad\text{(T0.9 inner-product expansion)}\\[4pt]
\Rightarrow \mathbb{E}[Z(x,y;w)] = \exp\!\Big( \tfrac12(|x|^2+|y|^2+2 x^\top y) - \tfrac12(|x|^2+|y|^2) \Big) = \exp(x^\top y)\\[6pt]
	ext{Now choose } x=\widehat q_i,\ y=\widehat k_j \text{ from T7.2. Then } x^\top y = \alpha_{ij}.\\[4pt]
\Rightarrow \mathbb{E}[Z(\widehat q_i,\widehat k_j;w)] = \exp(\alpha_{ij})\\[6pt]
\Rightarrow \mathbb{E}\Big[ \widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(\widehat q_i,\widehat k_j) \Big] = \frac{1}{n_{\mathrm{rf}}} \sum_{t=1}^{n_{\mathrm{rf}}} \mathbb{E}[Z(\widehat q_i,\widehat k_j;w_t)] = \exp(\alpha_{ij})\\[6pt]
\Note{ \widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(\widehat q_i,\widehat k_j) is an \emph{unbiased} positive estimator of \(\exp(\alpha_{ij})\), the \emph{unnormalized} softmax score. No claim is made here about the unbiasedness of the \emph{normalized} attention weight \(\exp(\alpha_{ij})/\sum_{j'}\exp(\alpha_{ij'})\), because that introduces a random denominator. }
}{T7.1,T7.2,T7.0,T0.9,T0.11}

\ProofBlock{T7.4:\mathbb{E}Z^2,\mathrm{Var}Z,\text{closed form}}{
	ext{Continue with fixed } x,y\in\Real^{d_{\mathrm{act}}}.\\[4pt]
Z(x,y;w) = \exp\!\Big( w^\top(x+y) - \tfrac12(|x|^2+|y|^2) \Big)\\
Z(x,y;w)^2 = \exp\!\Big( 2w^\top(x+y) - (|x|^2+|y|^2) \Big)\\[4pt]
\mathbb{E}[Z(x,y;w)^2] = \exp\!\Big( \tfrac12|2(x+y)|^2 - (|x|^2+|y|^2) \Big) = \exp\!\Big( 2|x+y|^2 - (|x|^2+|y|^2) \Big)\\[4pt]
|x+y|^2 = |x|^2+|y|^2+2 x^\top y \text{ (as used in T7.3)}\\[4pt]
\Rightarrow 2|x+y|^2 - (|x|^2+|y|^2) = 2(|x|^2+|y|^2+2 x^\top y) - (|x|^2+|y|^2) = |x|^2 + |y|^2 + 4 x^\top y\\[4pt]
\Rightarrow \mathbb{E}[Z(x,y;w)^2] = \exp\!\Big( |x|^2 + |y|^2 + 4 x^\top y \Big)\\[6pt]
\mathbb{E}[Z(x,y;w)] = \exp(x^\top y) \quad\text{from T7.3}\\
(\mathbb{E}[Z(x,y;w)])^2 = \exp(2 x^\top y)\\[4pt]
\mathrm{Var}[Z(x,y;w)] = \mathbb{E}[Z(x,y;w)^2] - (\mathbb{E}[Z(x,y;w)])^2\\[2pt]
= \exp\!\Big( |x|^2 + |y|^2 + 4 x^\top y \Big) - \exp\!\Big( 2 x^\top y \Big)\\[6pt]
\mathrm{Var}[Z(x,y;w)] = \exp\!\Big( 2 x^\top y \Big) \Big[ \exp\!\Big( |x|^2 + |y|^2 + 2 x^\top y \Big) - 1 \Big]\\[4pt]
\Note{ The single-sample variance is finite and given in closed form for all finite \(x,y\). }
}{T7.3,T7.1,T7.0,T0.9}

\ProofBlock{T7.5:\mathrm{Var}\ \widehat{\mathrm{SM}}_{n_{\mathrm{rf}}},\text{geom link}}{
	ext{The draws } w_t \text{ in T7.1 are i.i.d., so the } Z(\cdot;w_t) \text{ are i.i.d.}\\[4pt]
\widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(x,y) = \frac{1}{n_{\mathrm{rf}}} \sum_{t=1}^{n_{\mathrm{rf}}} Z(x,y;w_t)\\[4pt]
\mathrm{Var}\Big[ \widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(x,y) \Big] = \frac{1}{n_{\mathrm{rf}}^2} \sum_{t=1}^{n_{\mathrm{rf}}} \mathrm{Var}[Z(x,y;w_t)] = \frac{1}{n_{\mathrm{rf}}} \mathrm{Var}[Z(x,y;w)] \quad\text{(i.i.d.\ variance scaling)}\\[6pt]
	ext{Insert the expression from T7.4:}\\[4pt]
\mathrm{Var}\Big[ \widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(x,y) \Big] = \frac{1}{n_{\mathrm{rf}}} \exp\!\Big( 2 x^\top y \Big) \Big[ \exp\!\Big( |x|^2+|y|^2+2 x^\top y \Big) - 1 \Big]\\[6pt]
	ext{Now specialise } x=\widehat q_i,\ y=\widehat k_j \text{ from T7.2. Then } x^\top y = \alpha_{ij}.\\[4pt]
\Rightarrow \mathrm{Var}\Big[ \widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(\widehat q_i,\widehat k_j) \Big] = \frac{1}{n_{\mathrm{rf}}} \exp\!\Big( 2 \alpha_{ij} \Big) \Big[ \exp\!\Big( |\widehat q_i|^2+|\widehat k_j|^2+2 \alpha_{ij} \Big) - 1 \Big]\\[6pt]
	ext{Relate } |\widehat q_i|,|\widehat k_j| \text{ back to geometric quantities already controlled in T5.10.}\\[4pt]
\widehat q_i = d_{\mathrm{act}}^{-1/4}\tilde q_i,\quad \widehat k_j = d_{\mathrm{act}}^{-1/4}\tilde k_j \text{ from T7.2} \Rightarrow |\widehat q_i|^2 + |\widehat k_j|^2 = d_{\mathrm{act}}^{-1/2} (|\tilde q_i|^2+|\tilde k_j|^2)\\[4pt]
	ilde q_i = \Pi_{\mathrm{act}} R_{\mathrm{sp}}(r_i) q_i^{(\mathrm{act})} \text{ and } \tilde k_j = \Pi_{\mathrm{act}} R_{\mathrm{sp}}(r_j) k_j^{(\mathrm{act})} \text{ from T4.3.}\\[4pt]
R_{\mathrm{sp}}(r) \in SO(d_h) \text{ (T3.5) so } |R_{\mathrm{sp}}(r)z| = |z| \text{ for all }z\in\Real^{d_h},\\
\Pi_{\mathrm{act}} \text{ is an orthogonal projector (T2.10) so } |\Pi_{\mathrm{act}} z|\le |z| \text{ for all }z.\\[4pt]
\Rightarrow |\tilde q_i| \le |q_i^{(\mathrm{act})}|, \quad |\tilde k_j| \le |k_j^{(\mathrm{act})}|\\[4pt]
\Rightarrow |\tilde q_i|^2 + |\tilde k_j|^2 \le |q_i^{(\mathrm{act})}|^2 + |k_j^{(\mathrm{act})}|^2\\[6pt]
\Note{ 1) The estimator \(\widehat{\mathrm{SM}}_{n_{\mathrm{rf}}}(\widehat q_i,\widehat k_j)\) is unbiased for \(\exp(\alpha_{ij})\) (T7.3).\\[4pt] 2) Its variance decays exactly as \(1/n_{\mathrm{rf}}\).\\[4pt] 3) The variance prefactor depends on \(\alpha_{ij}\), \(|\widehat q_i|^2+|\widehat k_j|^2 = d_{\mathrm{act}}^{-1/2}(|\tilde q_i|^2+|\tilde k_j|^2)\), and thus is controlled by \(|q_i^{(\mathrm{act})}|\) and \(|k_j^{(\mathrm{act})}|\), which already enter the geometric stability bound T5.10.\\[4pt] 4) Under standard attention scaling, \(\alpha_{ij} = O(1)\) as \(d_{\mathrm{act}}\) grows, and \(|q_i^{(\mathrm{act})}|\), \(|k_j^{(\mathrm{act})}|\) scale so that \(|\widehat q_i|^2\) and \(|\widehat k_j|^2\) remain \(O(1)\). Hence the exponential factor in the variance is not pathological. }
}{T7.4,T7.2,T7.1,T4.3,T4.2,T3.5,T2.10,T0.9,T0.3,T0.6}
